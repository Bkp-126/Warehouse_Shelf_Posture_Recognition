import cv2
import time
import os
import json
import csv
import torch
import numpy as np
from datetime import datetime
from PySide6.QtCore import QThread, Signal, Slot
from PySide6.QtGui import QImage
from src.core_inference import PoseDetector


class AIWorker(QThread):
    frame_signal = Signal(QImage)
    stats_signal = Signal(dict)
    log_signal = Signal(str)
    finished_signal = Signal()

    def __init__(self, model_path, video_path):
        super().__init__()
        self.model_path = model_path
        self.video_path = video_path
        self.running = True

        self.show_roi = True
        self.show_skeleton = True
        self.show_angles = False

        # ROI é…ç½®
        self.config_path = os.path.join(os.path.dirname(video_path), "roi_config.json")
        self.roi_left = []
        self.roi_right = []
        self.load_config()

        self.counters = {"reach": 0, "bend": 0}
        self.state_memory = {"is_reaching": False, "is_bending": False}

        # --- ğŸ“‚ ä¿®å¤ï¼šç»å¯¹è·¯å¾„è¾“å‡º ---
        # è·å–å½“å‰è¿è¡Œè„šæœ¬çš„æ ¹ç›®å½• (å³ main_window.py è¿è¡Œçš„åœ°æ–¹)
        # os.getcwd() é€šå¸¸æ˜¯é¡¹ç›®æ ¹ç›®å½• D:\AI_Project\Warehouse...
        self.project_root = os.getcwd()
        self.output_dir = os.path.join(self.project_root, "output")
        self.img_dir = os.path.join(self.output_dir, "images")
        self.csv_path = os.path.join(self.output_dir, "report.csv")

        # è‡ªåŠ¨åˆ›å»ºç›®å½•
        os.makedirs(self.img_dir, exist_ok=True)

        # ğŸ”´ å¼ºåˆ¶æ‰“å°è·¯å¾„ï¼Œè®©ä½ ä¸€çœ¼çœ‹åˆ°
        print(f"\n[SYSTEM] è¯æ®ä¿å­˜è·¯å¾„å·²é”å®š: {self.output_dir}")
        print(f"[SYSTEM] CSV æŠ¥è¡¨è·¯å¾„: {self.csv_path}")

        # åˆå§‹åŒ– CSV è¡¨å¤´
        if not os.path.exists(self.csv_path):
            with open(self.csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(["æ—¶é—´", "äº‹ä»¶ç±»å‹", "å½“å‰è®¡æ•°", "å›¾ç‰‡æ–‡ä»¶å"])

    def load_config(self):
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.roi_left = data.get("left", [])
                    self.roi_right = data.get("right", [])
            except:
                pass

    def save_config(self):
        data = {"left": self.roi_left, "right": self.roi_right}
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=4)
        except:
            pass

    def save_evidence(self, frame, event_type, count):
        """ä¿å­˜è¯æ®"""
        try:
            now = datetime.now()
            time_str = now.strftime("%Y-%m-%d %H:%M:%S")
            file_time = now.strftime("%Y%m%d_%H%M%S")

            img_name = f"{event_type}_{file_time}.jpg"
            img_full_path = os.path.join(self.img_dir, img_name)

            # ä¿å­˜å›¾ç‰‡
            cv2.imwrite(img_full_path, frame)

            # è¿½åŠ  CSV
            with open(self.csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow([time_str, event_type, count, img_name])

            print(f"[SAVED] {img_full_path}")  # æ§åˆ¶å°ç¡®è®¤
            self.log_signal.emit(f"ğŸ’¾ å·²æŠ“æ‹: {img_name}")

        except Exception as e:
            print(f"[ERROR] ä¿å­˜å¤±è´¥: {e}")
            self.log_signal.emit(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    @Slot(str, bool)
    def update_settings(self, key, value):
        if key == "roi":
            self.show_roi = value
        elif key == "skeleton":
            self.show_skeleton = value
        elif key == "angles":
            self.show_angles = value

    @Slot(str, list)
    def update_roi(self, side, points):
        if side == "left":
            self.roi_left = points
        elif side == "right":
            self.roi_right = points
        self.save_config()
        self.log_signal.emit(f"âœ… {side} ROI æ›´æ–°")

    def run(self):
        if not os.path.exists(self.video_path): return

        # æ˜¾å¡é€‰æ‹©
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        try:
            detector = PoseDetector(self.model_path, device=device)
            self.log_signal.emit(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ ({device})")
        except Exception as e:
            self.log_signal.emit(f"âŒ {e}")
            return

        cap = cv2.VideoCapture(self.video_path)
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        if video_fps <= 0: video_fps = 30
        frame_interval = 1.0 / video_fps

        self.log_signal.emit(f"ğŸ¥ ç›‘æ§å·²å¯åŠ¨ (è¾“å‡ºç›®å½•: output/)")

        while self.running:
            t_start = time.time()
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue

            results, _ = detector.process_frame(frame)
            canvas = frame.copy()
            h, w = canvas.shape[:2]

            # åæ ‡å¤„ç†
            cnt_left = None;
            cnt_right = None
            if len(self.roi_left) >= 3:
                cnt_left = np.array([(int(nx * w), int(ny * h)) for (nx, ny) in self.roi_left], np.int32)
            if len(self.roi_right) >= 3:
                cnt_right = np.array([(int(nx * w), int(ny * h)) for (nx, ny) in self.roi_right], np.int32)

            trigger_left = False;
            trigger_right = False
            current_worker_count = len(results.boxes) if results.boxes else 0

            # ç»˜åˆ¶ä¸æ£€æµ‹é€»è¾‘
            if results.keypoints is not None:
                for kps in results.keypoints.data:
                    kps = kps.cpu().numpy()

                    # 1. ä¼¸æ‰‹
                    left_wrist = (int(kps[9][0]), int(kps[9][1]))
                    right_wrist = (int(kps[10][0]), int(kps[10][1]))
                    p_trigger_L = False;
                    p_trigger_R = False

                    if kps[9][2] > 0.5:
                        if (cnt_left is not None and cv2.pointPolygonTest(cnt_left, left_wrist, False) > 0) or \
                                (cnt_right is not None and cv2.pointPolygonTest(cnt_right, left_wrist, False) > 0):
                            trigger_left = True;
                            p_trigger_L = True
                    if kps[10][2] > 0.5:
                        if (cnt_left is not None and cv2.pointPolygonTest(cnt_left, right_wrist, False) > 0) or \
                                (cnt_right is not None and cv2.pointPolygonTest(cnt_right, right_wrist, False) > 0):
                            trigger_right = True;
                            p_trigger_R = True

                    # 2. å¼¯è…° (æ˜¾ç¤ºé€»è¾‘)
                    if kps[6][2] > 0.5 and kps[12][2] > 0.5 and kps[14][2] > 0.5:
                        angle = detector.calculate_angle(kps[6][:2], kps[12][:2], kps[14][:2])
                        if angle < 140:
                            cv2.putText(canvas, f"BEND {int(angle)}", (int(kps[12][0]), int(kps[12][1] - 20)),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

                    # 3. é«˜äº® (Reach)
                    color_core = (0, 255, 255);
                    color_glow = (255, 255, 0)
                    if p_trigger_L and kps[7][2] > 0.5:
                        cv2.line(canvas, left_wrist, (int(kps[7][0]), int(kps[7][1])), color_glow, 10)
                        cv2.line(canvas, left_wrist, (int(kps[7][0]), int(kps[7][1])), color_core, 4)
                        cv2.putText(canvas, "REACH", (left_wrist[0], left_wrist[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                    color_core, 2)
                    if p_trigger_R and kps[8][2] > 0.5:
                        cv2.line(canvas, right_wrist, (int(kps[8][0]), int(kps[8][1])), color_glow, 10)
                        cv2.line(canvas, right_wrist, (int(kps[8][0]), int(kps[8][1])), color_core, 4)
                        cv2.putText(canvas, "REACH", (right_wrist[0], right_wrist[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                                    color_core, 2)

                    # 4. éª¨æ¶
                    if self.show_skeleton:
                        for x, y, conf in kps:
                            if conf > 0.5: cv2.circle(canvas, (int(x), int(y)), 4, (0, 255, 0), -1)
                        links = [(5, 7), (7, 9), (6, 8), (8, 10), (5, 6), (5, 11), (6, 12), (11, 12), (11, 13),
                                 (13, 15), (12, 14), (14, 16)]
                        for p1, p2 in links:
                            if p1 < len(kps) and p2 < len(kps) and kps[p1][2] > 0.5 and kps[p2][2] > 0.5:
                                cv2.line(canvas, (int(kps[p1][0]), int(kps[p1][1])), (int(kps[p2][0]), int(kps[p2][1])),
                                         (255, 0, 255), 2)

            # çŠ¶æ€æœºä¸ä¿å­˜
            frame_has_reach = trigger_left or trigger_right
            if frame_has_reach and not self.state_memory["is_reaching"]:
                self.counters["reach"] += 1
                self.log_signal.emit(f"âš ï¸ ä¼¸æ‰‹å·¥ä½œ +1")
                self.save_evidence(canvas, "REACH", self.counters["reach"])  # ä¿å­˜!
                self.state_memory["is_reaching"] = True
            elif not frame_has_reach:
                self.state_memory["is_reaching"] = False

            # å¼¯è…°é€»è¾‘ (éœ€è¦éå†æ‰€æœ‰äººæ£€æŸ¥æ˜¯å¦æœ‰å¼¯è…°ï¼Œæ­¤å¤„ç®€åŒ–ä¸ºåªè¦ç”»é¢æœ‰å¼¯è…°å°±è§¦å‘)
            # åœ¨ä¸Šé¢çš„å¾ªç¯é‡Œå…¶å®å·²ç»ç”»äº† BENDï¼Œè¿™é‡ŒåšçŠ¶æ€åˆ¤å®šéœ€è¦æ›´ä¸¥è°¨ï¼Œ
            # ä¸ºç®€åŒ–ä»£ç ï¼Œæˆ‘ä»¬å‡è®¾å‰é¢æ£€æµ‹åˆ° BEND æ–‡å­—ç»˜åˆ¶å°±è§†ä½œå¼¯è…°
            # ä½†æ›´ä¸¥è°¨çš„æ˜¯åœ¨å¾ªç¯é‡Œç«‹ flag
            any_bend = False
            if results.keypoints is not None:
                for kps in results.keypoints.data:
                    kps = kps.cpu().numpy()
                    if kps[6][2] > 0.5 and kps[12][2] > 0.5 and kps[14][2] > 0.5:
                        if detector.calculate_angle(kps[6][:2], kps[12][:2], kps[14][:2]) < 140:
                            any_bend = True
                            break

            if any_bend and not self.state_memory["is_bending"]:
                self.counters["bend"] += 1
                self.log_signal.emit(f"âš ï¸ å¼¯è…°å·¥ä½œ +1")
                self.save_evidence(canvas, "BEND", self.counters["bend"])  # ä¿å­˜!
                self.state_memory["is_bending"] = True
            elif not any_bend:
                self.state_memory["is_bending"] = False

            # ROI ç»˜åˆ¶
            if self.show_roi:
                if cnt_left is not None:
                    cv2.polylines(canvas, [cnt_left], True, (0, 0, 255) if trigger_left else (0, 255, 255), 2)
                    cv2.putText(canvas, "LEFT", tuple(cnt_left[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                if cnt_right is not None:
                    cv2.polylines(canvas, [cnt_right], True, (0, 0, 255) if trigger_right else (0, 255, 255), 2)
                    cv2.putText(canvas, "RIGHT", tuple(cnt_right[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)
            qt_img = QImage(rgb.data, w, h, w * 3, QImage.Format_RGB888).copy()
            self.frame_signal.emit(qt_img)
            self.stats_signal.emit({"worker_count": current_worker_count, "reach_count": self.counters["reach"],
                                    "bend_count": self.counters["bend"]})

            t_end = time.time()
            if (t_end - t_start) < frame_interval: time.sleep(frame_interval - (t_end - t_start))

        cap.release()
        self.log_signal.emit("â¹ åœæ­¢")
        self.finished_signal.emit()

    def stop(self):
        self.running = False
        self.wait()